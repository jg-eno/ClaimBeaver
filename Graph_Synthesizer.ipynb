{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(openai_api_base= \"http://192.168.4.46:1234/v1\",\n",
    "    openai_api_key=key,\n",
    "    model_name=\"meta-llama-3.1-8b-instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def extract_metadata(df):\n",
    "    metadata = {}\n",
    "\n",
    "    # Number of columns\n",
    "    metadata['Number of Columns'] = df.shape[1]\n",
    "\n",
    "    # Column names\n",
    "    metadata['Schema'] = df.columns.tolist()\n",
    "\n",
    "    # Data types of each column\n",
    "    metadata['Data Types'] = str(df.dtypes)\n",
    "\n",
    "    # Summary statistics\n",
    "    metadata['Sample'] = df.head(1).to_dict(orient=\"records\")\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mtcars.csv\")\n",
    "metadata = extract_metadata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of Columns': 12,\n",
       " 'Schema': ['model',\n",
       "  'mpg',\n",
       "  'cyl',\n",
       "  'disp',\n",
       "  'hp',\n",
       "  'drat',\n",
       "  'wt',\n",
       "  'qsec',\n",
       "  'vs',\n",
       "  'am',\n",
       "  'gear',\n",
       "  'carb'],\n",
       " 'Data Types': 'model     object\\nmpg      float64\\ncyl        int64\\ndisp     float64\\nhp         int64\\ndrat     float64\\nwt       float64\\nqsec     float64\\nvs         int64\\nam         int64\\ngear       int64\\ncarb       int64\\ndtype: object',\n",
       " 'Sample': [{'model': 'Mazda RX4',\n",
       "   'mpg': 21.0,\n",
       "   'cyl': 6,\n",
       "   'disp': 160.0,\n",
       "   'hp': 110,\n",
       "   'drat': 3.9,\n",
       "   'wt': 2.62,\n",
       "   'qsec': 16.46,\n",
       "   'vs': 0,\n",
       "   'am': 1,\n",
       "   'gear': 4,\n",
       "   'carb': 4}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "Assistant is an AI model that takes in metadata from a dataset \n",
    "and suggests charts to use to visualise that data.\n",
    "\n",
    "New Input: Suggest 2 charts to visualise data from a dataset with the following metadata. \n",
    "\n",
    "\n",
    "SCHEMA:\n",
    "\n",
    "-------- \n",
    "\n",
    "{schema}\n",
    "\n",
    "DATA TYPES: \n",
    "\n",
    "-------- \n",
    "\n",
    "{data_types}\n",
    "\n",
    "SAMPLE: \n",
    "\n",
    "-------- \n",
    "\n",
    "{sample}\n",
    "\n",
    "'''.format(schema = metadata[\"Schema\"], data_types = metadata[\"Data Types\"], sample=metadata[\"Sample\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the metadata provided, here are two chart suggestions to visualize the data:\\n\\n**Chart 1: Scatter Plot of MPG vs Displacement**\\n\\n* X-axis: displacement (disp)\\n* Y-axis: miles per gallon (mpg)\\n* Color by: model\\n* This chart can help identify any relationships between engine size and fuel efficiency. We can see if larger engines tend to have better or worse fuel economy.\\n\\n**Chart 2: Bar Chart of Fuel Efficiency by Cylinders**\\n\\n* X-axis: number of cylinders (cyl)\\n* Y-axis: average miles per gallon (mpg)\\n* This chart can help identify the most fuel-efficient engine configuration. We can see if cars with more or fewer cylinders tend to have better fuel economy.\\n\\nThese charts will provide insights into two important aspects of vehicle performance: fuel efficiency and engine design.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt_template).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Create an instance of PythonREPL\n",
    "repl = PythonREPL()\n",
    "\n",
    "# Pass the dataframe into the globals dictionary of the PythonREPL instance\n",
    "repl.globals['df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n",
    "\n",
    "tools = [python_repl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_template = '''\n",
    "\n",
    "You are an agent that writes and excutes python code\n",
    "\n",
    "You have access to a Python abstract REPL, which you can use to execute the python code.\n",
    "\n",
    "You must write the python code code assuming that the dataframe (stored as df) has already been read.\n",
    "\n",
    "If you get an error, debug your code and try again.\n",
    "\n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "\n",
    "Do not create example dataframes \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_template = '''\n",
    "\n",
    "    {instructions_template}\n",
    "\n",
    "    TOOLS:\n",
    "\n",
    "    ------\n",
    "\n",
    "    You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    To use a tool, please use the following format:\n",
    "\n",
    "    ```\n",
    "\n",
    "    Thought: Do I need to use a tool? Yes\n",
    "\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "    Action Input: the input to the action\n",
    "\n",
    "    Observation: the result of the action\n",
    "\n",
    "    ```\n",
    "\n",
    "    When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "    ```\n",
    "\n",
    "    Thought: Do I need to use a tool? No\n",
    "\n",
    "    Final Answer: [your response here]\n",
    "\n",
    "    ```\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Previous conversation history:\n",
    "\n",
    "    {chat_history}\n",
    "\n",
    "    New input: {input}\n",
    "\n",
    "    {agent_scratchpad}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "base_prompt = PromptTemplate(template=base_template, input_variables=['agent_scratchpad', 'input', 'instructions', 'tool_names', 'tools'])\n",
    "base_prompt = base_prompt.partial(instructions_template=instructions_template) #format the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = '''\n",
    "Create the data needed for the following chart\n",
    "\n",
    "CHART \n",
    "\n",
    "-------- \n",
    "Chart 1: Bar Chart - Top 10 cars\n",
    "\n",
    "X-axis: model names\n",
    "\n",
    "Y-axis: carb\\n*\n",
    "\n",
    "You're task is to write code to transform the raw data into the desired data structure in json to be included in the plot.\n",
    "\n",
    "Only return the data.\n",
    "\n",
    "Here is the dataset schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "'''.format(schema=metadata['Schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "\n",
      "Final Answer:\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "df_top_10_cars = df.nlargest(10, 'mpg')[['model', 'carb']]\n",
      "df_top_10_cars_json = df_top_10_cars.to_json(orient='records')\n",
      "\n",
      "print(df_top_10_cars_json)\n",
      "```\n",
      "This will output a JSON string containing the top 10 cars by MPG along with their carb count.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "agent = create_react_agent(llm, tools, base_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_out = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": new_input,\n",
    "        \"chat_history\": \"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```python\\nimport pandas as pd\\n\\n# Assuming the dataframe is stored in df and it has a column for winery names and another for points\\nwineries_data = df.groupby('Winery Name')['Points'].mean().reset_index()\\nwineries_data = wineries_data.nlargest(10, 'Points')\\nwineries_data['Average Points'] = wineries_data['Points']\\nwineries_data = wineries_data[['Winery Name', 'Average Points']]\\nwineries_data = wineries_data.to_json(orient='records')\\n\\nprint(wineries_data)\\n```\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_out['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"model\":\"Toyota Corolla\",\"carb\":1},{\"model\":\"Fiat 128\",\"carb\":1},{\"model\":\"Honda Civic\",\"carb\":2},{\"model\":\"Lotus Europa\",\"carb\":2},{\"model\":\"Fiat X1-9\",\"carb\":1},{\"model\":\"Porsche 914-2\",\"carb\":2},{\"model\":\"Merc 240D\",\"carb\":2},{\"model\":\"Datsun 710\",\"carb\":1},{\"model\":\"Merc 230\",\"carb\":2},{\"model\":\"Toyota Corona\",\"carb\":1}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_top_10_cars = df.nlargest(10, 'mpg')[['model', 'carb']]\n",
    "df_top_10_cars_json = df_top_10_cars.to_json(orient='records')\n",
    "\n",
    "print(df_top_10_cars_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphMaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
